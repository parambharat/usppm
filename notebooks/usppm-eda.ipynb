{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import expit\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import transformers\n",
    "import warnings\n",
    "import logging\n",
    "import torch\n",
    "warnings.simplefilter('ignore')\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import datasets\n",
    "\n",
    "from coral_pytorch.losses import coral_loss\n",
    "from coral_pytorch.dataset import levels_from_labelbatch\n",
    "from coral_pytorch.dataset import proba_to_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init and data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    project_name=\"usppm\",\n",
    "    entity=\"parambharat\",\n",
    "    group=\"usppm-hf\",\n",
    "    model_name_or_path=\"anferico/bert-for-patents\", # \"distilbert-base-uncased\", \"anferico/bert-for-patents\", #  \"microsoft/deberta-v3-small\",\n",
    "    problem_type=\"regression\", # \"regression\", #regression, multi_label_classification\n",
    "    val_size=0.25,\n",
    "    learning_rate=3e-6,\n",
    "    batch_size=64,\n",
    "    weight_decay=0.01,\n",
    "    epochs = 5,\n",
    "    data_dir=\"../data\",\n",
    "    log_dir = \"../logs\",\n",
    "    output_dir=\"../outputs\",\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    \n",
    "    \n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "run = wandb.init(project=config[\"project_name\"], entity=config[\"entity\"], config=config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(run.config.data_dir + \"/train.csv\").sample(frac=1, random_state=42)\n",
    "test_data = pd.read_csv(run.config.data_dir +\"/test.csv\").sample(frac=1, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EDA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def enrich_metadata(data:pd.DataFrame)->pd.DataFrame:\n",
    "    context_mapping = {\n",
    "            \"A\": \"Human Necessities\",\n",
    "            \"B\": \"Operations and Transport\",\n",
    "            \"C\": \"Chemistry and Metallurgy\",\n",
    "            \"D\": \"Textiles\",\n",
    "            \"E\": \"Fixed Constructions\",\n",
    "            \"F\": \"Mechanical Engineering\",\n",
    "            \"G\": \"Physics\",\n",
    "            \"H\": \"Electricity\",\n",
    "            \"Y\": \"Emerging Cross-Sectional Technologies\",\n",
    "        }\n",
    "    data.loc[:, \"context_desc\"] = data[\"context\"].apply(lambda x: context_mapping[x[0]])\n",
    "    data.loc[:, \"anchor_length\"] = data[\"anchor\"].str.split().map(len)\n",
    "    data.loc[:, \"target_length\"] = data[\"target\"].str.split().map(len)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data = enrich_metadata(train_data)\n",
    "test_data = enrich_metadata(test_data)\n",
    "\n",
    "train_table = wandb.Table(dataframe=train_data)\n",
    "test_table = wandb.Table(dataframe=test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run.log({\"train_dataset\": train_table, \"test_dataset\": test_table})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def log_col_stats(df:pd.DataFrame, col:str):\n",
    "    stats_df = (\n",
    "        pd.DataFrame(df[col].value_counts())\n",
    "        .reset_index()\n",
    "        .rename({\"index\":col, col: \"count\"}, axis=1)\n",
    "        .sort_values(\"count\", ascending=False)\n",
    "    )\n",
    "    table = wandb.Table(dataframe=stats_df)\n",
    "    return wandb.log({f\"{col}_counts\": table})\n",
    "    \n",
    "for col in train_data.columns:\n",
    "    if col not in [\"id\"]:\n",
    "        log_col_stats(train_data, col)\n",
    "        \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training and Validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "intersection = np.intersect1d(train_data.anchor.unique(), test_data.anchor.unique())\n",
    "intersection.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sgkf = StratifiedGroupKFold(n_splits=int(1/run.config.val_size))\n",
    "train_index, val_index = next(sgkf.split(train_data, train_data[\"score\"]*100, train_data.anchor))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def convert_df_to_dataset(data_df, stage=\"train\", problem_type=\"regression\"):\n",
    "    if stage == \"train\":\n",
    "        if problem_type == \"single_label_classification\":\n",
    "            data_df.loc[:, \"score\"] = (data_df[\"score\"] * (data_df[\"score\"].nunique()-1)).astype(int)\n",
    "            \n",
    "        elif problem_type == \"multi_label_classification\":\n",
    "            data_df.loc[:, \"score\"] = (data_df[\"score\"] * (data_df[\"score\"].nunique()-1)).astype(int)\n",
    "#             score_mat = np.zeros((data_df.shape[0],4), dtype=int)\n",
    "#             for i, item in enumerate(data_df.score.tolist()):\n",
    "#                 score_mat[i,:item]=1\n",
    "            data_df.loc[:, \"score\"] = pd.Series(\n",
    "                levels_from_labelbatch(data_df.score, data_df[\"score\"].nunique())\n",
    "                .numpy().tolist())\n",
    "        \n",
    "        cols = [\"anchor\", \"target\", \"context_desc\", \"score\"]\n",
    "        data_df = data_df[cols].rename({\"score\": \"label\"}, axis=1)\n",
    "    else:\n",
    "        cols = [\"anchor\", \"target\", \"context_desc\"]\n",
    "        data_df = data_df[cols]\n",
    "    data_df[\"inputs\"] = (\n",
    "        \"in the context of \" +\n",
    "        data_df[\"context_desc\"]  +\n",
    "        \" how similar is \" +\n",
    "        data_df[\"anchor\"] +\n",
    "        \" to \" +\n",
    "        data_df[\"target\"]\n",
    "    )\n",
    "\n",
    "    dataset = datasets.Dataset.from_pandas(data_df, preserve_index=False)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = convert_df_to_dataset(train_data.copy(), problem_type=run.config.problem_type)\n",
    "\n",
    "experiment_datasets = datasets.DatasetDict({\n",
    "    \"train\":train_dataset.select(train_index),\n",
    "    \"validation\": train_dataset.select(val_index)}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(run.config.model_name_or_path)\n",
    "\n",
    "def tokenizer_fn(examples):\n",
    "    return tokenizer(examples[\"inputs\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dropped_cols = [col for col in [\"inputs\", \"anchor\", \"target\", \"context_desc\", \"label\"] if not col == \"label\"]\n",
    "preprocessed_datasets = experiment_datasets.map(\n",
    "    tokenizer_fn, \n",
    "    batched=True,\n",
    "    remove_columns=dropped_cols,\n",
    "    num_proc=10,\n",
    "#     batch_size=100\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pearson_corr_reg(eval_pred):\n",
    "    predictions = eval_pred.predictions.flatten()\n",
    "    labels = eval_pred.label_ids\n",
    "    return {'pearson': np.corrcoef(labels, predictions)[0][1]}\n",
    "\n",
    "def pearson_corr_clf(eval_pred):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1).flatten().astype(float)\n",
    "    labels = eval_pred.label_ids.astype(float)    \n",
    "    return {'pearson': np.corrcoef(predictions, labels)[0][1]}\n",
    "\n",
    "def pearson_corr_ord(eval_pred):\n",
    "    predictions = proba_to_label(torch.Tensor(expit(eval_pred.predictions))).numpy()\n",
    "    labels = eval_pred.label_ids\n",
    "    labels = (labels==0).argmax(axis=1)\n",
    "    print(predictions[:10])\n",
    "    print(labels[:10])\n",
    "    return {'pearson': np.corrcoef(predictions, labels)[0][1]}\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    run.config.output_dir,\n",
    "    learning_rate=run.config.learning_rate, \n",
    "    warmup_ratio=run.config.warmup_ratio,\n",
    "    lr_scheduler_type=run.config.lr_scheduler_type,\n",
    "    per_device_train_batch_size=run.config.batch_size,\n",
    "    per_device_eval_batch_size=run.config.batch_size,\n",
    "    num_train_epochs=run.config.epochs,\n",
    "    weight_decay=run.config.weight_decay,\n",
    "    report_to=\"wandb\",\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "if run.config.problem_type == \"regression\":\n",
    "    run.config.num_labels = 1\n",
    "    metric_fn = pearson_corr_reg\n",
    "\n",
    "elif run.config.problem_type == \"single_label_classification\":\n",
    "    run.config.num_labels = train_data.score.nunique()\n",
    "    metric_fn = pearson_corr_clf\n",
    "    \n",
    "elif run.config.problem_type == \"multi_label_classification\":\n",
    "    run.config.num_labels = train_data.score.nunique()-1\n",
    "    metric_fn = pearson_corr_ord\n",
    "    \n",
    "def model_init():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        run.config.model_name_or_path,\n",
    "        num_labels=run.config.num_labels,\n",
    "        problem_type=run.config.problem_type\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "class CoralTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss = coral_loss(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "trainer = CoralTrainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=preprocessed_datasets['train'],\n",
    "    eval_dataset=preprocessed_datasets['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=metric_fn,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.hyperparameter_search(\n",
    "    direction=\"maximize\", \n",
    "    backend=\"wandb\",\n",
    "    n_trials=10, # number of trials\n",
    "    project = run.config.project_name,\n",
    "    entity = run.config.entity,\n",
    "    metric = \"pearson\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = convert_df_to_dataset(test_data, stage=\"test\", problem_type=run.config.problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataset = test_dataset.map(\n",
    "    tokenizer_fn, \n",
    "    batched=True,\n",
    "    remove_columns=dropped_cols,\n",
    "    num_proc=10,\n",
    "    batch_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.config.problem_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.config.problem_type = config[\"problem_type\"] if not run.config.problem_type else run.config.problem_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset, problem_type=\"regression\"):\n",
    "    model_outputs = trainer.predict(dataset)\n",
    "    if problem_type == \"regression\":\n",
    "        predictions = model_outputs.predictions.flatten().clip(0,1)\n",
    "    elif problem_type == \"single_label_classification\":\n",
    "        predictions = np.argmax(model_outputs.predictions, axis=1)\n",
    "        predictions = predictions / (run.config.num_labels -1)\n",
    "    elif problem_type == \"multi_label_classification\":\n",
    "        predictions = (expit(model_outputs.predictions) > 0.5).astype(int)\n",
    "        predictions = expit(model_outputs.predictions)\n",
    "#         predictions = (predictions==0).argmax(axis=1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(inference_dataset, problem_type=run.config.problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = predict(inference_dataset, problem_type=run.config.problem_type)\n",
    "# val_predictions = predict(preprocessed_datasets[\"validation\"], problem_type=run.config.problem_type)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = train_data.iloc[val_index]\n",
    "\n",
    "val_data.loc[:, \"prediction\"] = val_predictions\n",
    "val_table = wandb.Table(dataframe=val_data)\n",
    "run.log({\"val_predictions\": val_table})\n",
    "\n",
    "\n",
    "test_data.loc[:, \"prediction\"] = test_predictions\n",
    "test_table = wandb.Table(dataframe=test_data)\n",
    "\n",
    "run.log({\"test_predictions\": test_table})\n",
    "\n",
    "\n",
    "submissions_df = test_data[[\"id\", 'prediction']].rename({\"prediction\": \"score\"}, axis=1)\n",
    "\n",
    "submission_fname = run.config.output_dir+\"/submission_\"+wandb.util.generate_id()+\".csv\"\n",
    "submissions_df.to_csv(submission_fname, index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}